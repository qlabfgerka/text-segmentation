{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchinfo\n",
    "import random\n",
    "import string\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "TRAIN_FOLDER = 'train/'\n",
    "TEST_FOLDER = 'test/'\n",
    "PHOTOS_FOLDER = 'photos/'\n",
    "\n",
    "EPOCHS = 1000\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-4\n",
    "IMAGES_PER_EPOCH = 1024\n",
    "SIZE = 256\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, X, Y):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect(torch.nn.Module):\n",
    "  def __init__(self, input, output) -> None:\n",
    "    super().__init__()\n",
    "    self.conv2d = torch.nn.Conv2d(input, output, kernel_size=(3, 3), padding=\"same\")\n",
    "    self.batchnorm2d = torch.nn.BatchNorm2d(output)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv2d(x)\n",
    "    x = self.batchnorm2d(x)\n",
    "    x = self.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(torch.nn.Module):\n",
    "  def __init__(self, input, output) -> None:\n",
    "    super().__init__()\n",
    "    self.first_connection = Connect(input, output)\n",
    "    self.second_connection = Connect(output, output)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.first_connection(x)\n",
    "    x = self.second_connection(x)\n",
    "    return x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpBlock(torch.nn.Module):\n",
    "  def __init__(self, input, output) -> None:\n",
    "    super().__init__()\n",
    "    self.convtranspose2d = torch.nn.ConvTranspose2d(input, output, kernel_size=(2, 2), stride=(2, 2), padding=0)\n",
    "    self.first_connection = Connect(input, output)\n",
    "    self.second_connection = Connect(output, output)\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    x = self.convtranspose2d(x)\n",
    "    x = torch.cat((y, x), dim=1)\n",
    "    x = self.first_connection(x)\n",
    "    x = self.second_connection(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.first_down_block = DownBlock(3, 32)\n",
    "    self.second_down_block = DownBlock(32, 64)\n",
    "    self.third_down_block = DownBlock(64, 128)\n",
    "    self.fourth_down_block = DownBlock(128, 256)\n",
    "\n",
    "    self.first_up_block = UpBlock(256, 128)\n",
    "    self.second_up_block = UpBlock(128, 64)\n",
    "    self.third_up_block = UpBlock(64, 32)\n",
    "\n",
    "    self.maxpool2d = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "    self.conv2d = torch.nn.Conv2d(32, 1, (1, 1), padding=\"same\")\n",
    "\n",
    "  def forward(self, x):\n",
    "    x, first_layer = self.first_down_block(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x, second_layer = self.second_down_block(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x, third_layer = self.third_down_block(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x, _ = self.fourth_down_block(x)\n",
    "\n",
    "    x = self.first_up_block(x, third_layer)\n",
    "    x = self.second_up_block(x, second_layer)\n",
    "    x = self.third_up_block(x, first_layer)\n",
    "    x = self.conv2d(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, title, cmap=\"viridis\"):\n",
    "  plt.imshow(image, cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(input, target, output):\n",
    "  red = np.full(target.shape[:2]+(3,), [1, 0, 0], dtype=np.float32)\n",
    "  green = np.full(target.shape[:2]+(3,), [0, 1, 0], dtype=np.float32)\n",
    "  diff = np.where(target == output, green, red)\n",
    "\n",
    "  _, axes = plt.subplots(1, 4, figsize=(15, 15), squeeze=False)\n",
    "  axes[0, 0].imshow(input)\n",
    "  axes[0, 0].set_title(\"Input\")\n",
    "  axes[0, 0].axis(\"off\")\n",
    "\n",
    "  axes[0, 1].imshow(target, cmap=\"gray\")\n",
    "  axes[0, 1].set_title(\"Target\")\n",
    "  axes[0, 1].axis(\"off\")\n",
    "\n",
    "  axes[0, 2].imshow(output, cmap=\"gray\")\n",
    "  axes[0, 2].set_title(\"Output\")\n",
    "  axes[0, 2].axis(\"off\")\n",
    "\n",
    "  axes[0, 3].imshow(diff)\n",
    "  axes[0, 3].set_title(\"Diff\")\n",
    "  axes[0, 3].axis(\"off\")\n",
    "\n",
    "  plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image(image):\n",
    "  image = image.astype(np.float32)\n",
    "  image = image / 255\n",
    "  image[image > 1] = 1\n",
    "  image[image < 0] = 0\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(image):\n",
    "  image = image.transpose(-1, 0, 1)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "  image = cv2.imread(path)\n",
    "\n",
    "  if image is not None:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return fix_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "  images = []\n",
    "  for filename in os.listdir(folder):\n",
    "    image = cv2.imread(os.path.join(folder, filename))\n",
    "    if image is not None:\n",
    "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "      images.append(fix_image(image))\n",
    "\n",
    "  return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(target, prediction):\n",
    "  target[target >= 0.5] = 1\n",
    "  target[target < 0.5] = 0\n",
    "\n",
    "  target = target[:,:,0]\n",
    "  prediction = prediction[:,:,0]\n",
    "\n",
    "  ones = np.sum(prediction[target == 1]) / np.size(prediction)\n",
    "  zeros = np.sum(prediction[target == 0]) / np.size(prediction)\n",
    "\n",
    "  return (ones + zeros) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(target, prediction):\n",
    "  target[target >= 0.5] = 1\n",
    "  target[target < 0.5] = 0\n",
    "\n",
    "  target = target[:,:,0]\n",
    "  prediction = prediction[:,:,0]\n",
    "\n",
    "  ones = 2.0 * np.sum(prediction[target == 1]) / (np.size(prediction) + np.size(target))\n",
    "  zeros = 2.0 * np.sum(prediction[target == 0]) / (np.size(prediction) + np.size(target))\n",
    "\n",
    "  return (ones + zeros) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_portion(image):\n",
    "  x1 = random.randint(0, image.shape[0] - SIZE * 2 - 1)\n",
    "  y1 = random.randint(0, image.shape[1] - SIZE * 2 - 1)\n",
    "\n",
    "  x2, y2 = x1 + SIZE * 2, y1 + SIZE * 2\n",
    "\n",
    "  return image[x1:x2, y1:y2, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(background, foreground, display=False):\n",
    "  background_portion = get_image_portion(background)\n",
    "  foreground_portion = get_image_portion(foreground)\n",
    "\n",
    "  text = ''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase + string.digits + ' ') for _ in range(random.randint(20, 50)))\n",
    "  text_location = (random.randint(SIZE / 2, SIZE), random.randint(SIZE / 2, SIZE))\n",
    "  fonts = [0, 1, 2, 3, 4, 5, 6, 7, 16]\n",
    "\n",
    "  mask = np.zeros((SIZE * 2, SIZE * 2, 3), dtype=np.float32)\n",
    "  cv2.putText(\n",
    "    mask, \n",
    "    text, \n",
    "    text_location,\n",
    "    random.choice(fonts),\n",
    "    random.uniform(1, 3),\n",
    "    (255, 255, 255),\n",
    "    random.randint(1, 5),\n",
    "    cv2.LINE_AA,\n",
    "    False\n",
    "  )\n",
    "  #mask = cv2.warpAffine(mask, cv2.getRotationMatrix2D(text_location, random.uniform(0, 360), 1), (mask.shape[1], mask.shape[0]))\n",
    "  mask = fix_image(mask)\n",
    "  input = (1 - mask) * background_portion + mask * foreground_portion\n",
    "\n",
    "  angle = random.randint(0, 360)\n",
    "  flip = random.randint(-1, 1)\n",
    "\n",
    "  mask = rotate_image(mask, angle)\n",
    "  input = rotate_image(input, angle)\n",
    "\n",
    "  mask = cv2.flip(mask, flip)\n",
    "  input = cv2.flip(input, flip)\n",
    "\n",
    "  mask[mask >= 0.5] = 1\n",
    "  mask[mask < 0.5] = 0\n",
    "\n",
    "  mask = mask[128:384, 128:384, 0:3]\n",
    "  input = input[128:384, 128:384, 0:3]\n",
    "\n",
    "  if display:\n",
    "    _, axes = plt.subplots(2, 3, figsize=(15, 15))\n",
    "    axes[0, 0].imshow(background)\n",
    "    axes[0, 0].set_title(\"Background \" + str(background.shape))\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    axes[0, 1].imshow(foreground)\n",
    "    axes[0, 1].set_title(\"Foreground \" + str(foreground.shape))\n",
    "    axes[0, 1].axis(\"off\")\n",
    "    \n",
    "    axes[0, 2].imshow(background_portion)\n",
    "    axes[0, 2].set_title(\"Background portion \" + str(background_portion.shape))\n",
    "    axes[0, 2].axis(\"off\")\n",
    "    \n",
    "    axes[1, 0].imshow(foreground_portion)\n",
    "    axes[1, 0].set_title(\"Foreground portion \" + str(foreground_portion.shape))\n",
    "    axes[1, 0].axis(\"off\")\n",
    "    \n",
    "    axes[1, 1].imshow(mask)\n",
    "    axes[1, 1].set_title(\"Target \" + str(mask.shape))\n",
    "    axes[1, 1].axis(\"off\")\n",
    "    \n",
    "    axes[1, 2].imshow(input)\n",
    "    axes[1, 2].set_title(\"Input \" + str(input.shape))\n",
    "    axes[1, 2].axis(\"off\")\n",
    "\n",
    "  return input, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  model = UNet()\n",
    "  model = model.to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "  images = load_images_from_folder(TRAIN_FOLDER)\n",
    "  print('IMAGES LOADED')\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "      print('epoch:' + str(epoch + 1) + ' of ' + str(EPOCHS))\n",
    "\n",
    "    for i in range(IMAGES_PER_EPOCH):\n",
    "      if (i + 1) % 128 == 0:\n",
    "        print('generating image: ' + str(i))\n",
    "      input, target = generate_images(random.choice(images), random.choice(images), i < 5 and epoch == 0)\n",
    "\n",
    "      inputs.append(input)\n",
    "      targets.append(target)\n",
    "\n",
    "    for i in range(len(inputs)):\n",
    "      inputs[i] = transpose(inputs[i])\n",
    "\n",
    "    for i in range(len(targets)):\n",
    "      targets[i] = transpose(targets[i])\n",
    "\n",
    "    dataset = ImageDataset(inputs, targets)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    for step, (input_batch, target_batch) in enumerate(dataloader):\n",
    "      if (step + 1) % 100 == 0:\n",
    "        print('training image:' + str(step + 1) + ' of ' + str(len(dataloader)))\n",
    "\n",
    "      input_batch = input_batch.to(device)\n",
    "      target_batch = target_batch.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      pred = model(input_batch)\n",
    "\n",
    "      loss = loss_fn(pred, target_batch[0:1, 0:1, 0:SIZE, 0:SIZE])\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "  torch.save(model, \"text-segmentation.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    output = model(input)\n",
    "    output = torch.sigmoid(output).round()\n",
    "    output = output.cpu().detach()\n",
    "    \n",
    "    return output.squeeze(0).permute(1, 2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generated(n, display=False):\n",
    "  model = torch.load(\"text-segmentation.pt\", map_location=device)\n",
    "  ious = []\n",
    "  dices = []\n",
    "\n",
    "  for _ in range(n):\n",
    "    background = load_image(TEST_FOLDER + random.choice(os.listdir(TEST_FOLDER)))\n",
    "    foreground = load_image(TEST_FOLDER + random.choice(os.listdir(TEST_FOLDER)))\n",
    "    input, target = generate_images(background, foreground, False)\n",
    "\n",
    "    input = torch.from_numpy(transpose(input)).unsqueeze(0).to(device)\n",
    "\n",
    "    prediction = predict(model, input).numpy()\n",
    "\n",
    "    ious.append(iou(target, prediction))\n",
    "    dices.append(dice(target, prediction))\n",
    "\n",
    "    if display:\n",
    "      print(f\"IOU: {iou(target, prediction):.4f}\\tDICE: {dice(target, prediction):.4f}\")\n",
    "      display_images(input.cpu().detach().squeeze().permute(1, 2, 0), target, prediction)\n",
    "\n",
    "  print(f\"IoU (povpreÄje +- standardni odklon): {np.mean(ious) :.2f} +- {np.std(ious) :.2f}\")\n",
    "  print(f\"Dice (povpreÄje +- standardni odklon): {np.mean(dices) :.2f} +- {np.std(dices) :.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_photos(display=True):\n",
    "  images = load_images_from_folder(PHOTOS_FOLDER)\n",
    "  model = torch.load(\"text-segmentation.pt\", map_location=device)\n",
    "\n",
    "  for image in images:\n",
    "    image = torch.from_numpy(transpose(image)).unsqueeze(0).to(device)\n",
    "\n",
    "    prediction = predict(model, image).numpy()\n",
    "    image = image.cpu().detach().squeeze().permute(1, 2, 0)\n",
    "\n",
    "    if display:\n",
    "      _, axes = plt.subplots(1, 2, figsize=(15, 15), squeeze=False)\n",
    "\n",
    "      axes[0, 0].imshow(image)\n",
    "      axes[0, 0].axis(\"off\")\n",
    "      axes[0, 0].set_title(\"Input\")\n",
    "      axes[0, 1].imshow(prediction, cmap=\"gray\")\n",
    "      axes[0, 1].axis(\"off\")\n",
    "      axes[0, 1].set_title(\"Output\")\n",
    "      plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#background = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "#foreground = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "#target, mask = generate_images(background, foreground, True)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"text-segmentation.pt\", map_location=device)\n",
    "torchinfo.summary(model, (1, 3, 256, 256), depth=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generated(3, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generated(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_photos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
