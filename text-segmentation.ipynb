{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torchinfo\n",
    "import random\n",
    "import string\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "TRAIN_FOLDER = 'train/'\n",
    "TEST_FOLDER = 'test/'\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "LR = 1e-4\n",
    "IMAGES_PER_EPOCH = 10\n",
    "SIZE = 256\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "  def __init__(self, X, Y):\n",
    "    self.X = X\n",
    "    self.Y = Y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    return self.X[index], self.Y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connect(torch.nn.Module):\n",
    "  def __init__(self, input, output) -> None:\n",
    "    super().__init__()\n",
    "    self.conv2d = torch.nn.Conv2d(input, output, kernel_size=(3, 3), padding=\"same\")\n",
    "    self.batchnorm2d = torch.nn.BatchNorm2d(output)\n",
    "    self.relu = torch.nn.ReLU()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.conv2d(x)\n",
    "    x = self.batchnorm2d(x)\n",
    "    x = self.relu(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(torch.nn.Module):\n",
    "  def __init__(self) -> None:\n",
    "    super().__init__()\n",
    "    self.connect3_32 = Connect(3, 32)\n",
    "    self.connect32_32 = Connect(32, 32)\n",
    "    self.connect32_32_2 = Connect(32, 32)\n",
    "    self.connect32_64 = Connect(32, 64)\n",
    "    self.connect64_64 = Connect(64, 64)\n",
    "    self.connect64_64_2 = Connect(64, 64)\n",
    "    self.connect64_128 = Connect(64, 128)\n",
    "    self.connect128_128 = Connect(128, 128)\n",
    "    self.connect128_128_2 = Connect(128, 128)\n",
    "    self.connect128_256 = Connect(128, 256)\n",
    "    self.connect256_256 = Connect(256, 256)\n",
    "    self.connect256_128 = Connect(256, 128)\n",
    "    self.connect128_64 = Connect(128, 64)\n",
    "    self.connect64_32 = Connect(64, 32)\n",
    "    self.maxpool2d = torch.nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "    self.conv2d = torch.nn.Conv2d(32, 1, (1, 1), padding=\"same\")\n",
    "    self.first_convtranspose2d = torch.nn.ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
    "    self.second_convtranspose2d = torch.nn.ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
    "    self.third_convtranspose2d = torch.nn.ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.connect3_32(x)\n",
    "    x = self.connect32_32(x)\n",
    "    first_layer = torch.clone(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x = self.connect32_64(x)\n",
    "    x = self.connect64_64(x)\n",
    "    second_layer = torch.clone(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x = self.connect64_128(x)\n",
    "    x = self.connect128_128(x)\n",
    "    third_layer = torch.clone(x)\n",
    "\n",
    "    x = self.maxpool2d(x)\n",
    "    x = self.connect128_256(x)\n",
    "    x = self.connect256_256(x)\n",
    "\n",
    "    x = self.first_convtranspose2d(x)\n",
    "    x = torch.cat((third_layer, x), dim=1)\n",
    "    x = self.connect256_128(x)\n",
    "    x = self.connect128_128_2(x)\n",
    "\n",
    "    x = self.second_convtranspose2d(x)\n",
    "    x = torch.cat((second_layer, x), dim=1)\n",
    "    x = self.connect128_64(x)\n",
    "    x = self.connect64_64_2(x)\n",
    "    \n",
    "    x = self.third_convtranspose2d(x)\n",
    "    x = torch.cat((first_layer, x), dim=1)\n",
    "    x = self.connect64_32(x)\n",
    "    x = self.connect32_32_2(x)\n",
    "    x = self.conv2d(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image, title, cmap=\"viridis\"):\n",
    "  plt.imshow(image, cmap=cmap)\n",
    "  plt.title(title)\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_image(image):\n",
    "  image = image / 255\n",
    "  image[image > 1] = 1\n",
    "  image[image < 0] = 0\n",
    "  image = image.astype(np.float32)\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(image):\n",
    "  image = image.transpose(-1, 0, 1)\n",
    "\n",
    "  return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "  image = cv2.imread(path, -1)\n",
    "\n",
    "  if image is not None:\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return fix_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_portion(image):\n",
    "  x1 = random.randint(0, image.shape[0] - SIZE * 2 - 1)\n",
    "  y1 = random.randint(0, image.shape[1] - SIZE * 2 - 1)\n",
    "\n",
    "  x2, y2 = x1 + SIZE * 2, y1 + SIZE * 2\n",
    "\n",
    "  return image[x1:x2, y1:y2, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(background, foreground, display=False):\n",
    "  background_portion = get_image_portion(background)\n",
    "  foreground_portion = get_image_portion(foreground)\n",
    "\n",
    "  text = ''.join(random.choice(string.ascii_lowercase + string.ascii_uppercase + string.digits + ' ') for _ in range(random.randint(20, 50)))\n",
    "  text_location = (random.randint(SIZE / 2, SIZE), random.randint(SIZE / 2, SIZE))\n",
    "  fonts = [0, 1, 2, 3, 4, 5, 6, 7, 16]\n",
    "\n",
    "  mask = np.zeros((SIZE * 2, SIZE * 2, 3), dtype=np.float32)\n",
    "  cv2.putText(\n",
    "    mask, \n",
    "    text, \n",
    "    text_location,\n",
    "    random.choice(fonts),\n",
    "    random.uniform(1, 3),\n",
    "    (255, 255, 255),\n",
    "    random.randint(1, 5),\n",
    "    cv2.LINE_AA,\n",
    "    False\n",
    "  )\n",
    "  #mask = cv2.warpAffine(mask, cv2.getRotationMatrix2D(text_location, random.uniform(0, 360), 1), (mask.shape[1], mask.shape[0]))\n",
    "  mask = fix_image(mask)\n",
    "  target = (1 - mask) * background_portion + mask * foreground_portion\n",
    "\n",
    "  angle = random.randint(0, 360)\n",
    "  flip = random.randint(-1, 1)\n",
    "\n",
    "  mask = rotate_image(mask, angle)\n",
    "  target = rotate_image(target, angle)\n",
    "\n",
    "  mask = cv2.flip(mask, flip)\n",
    "  target = cv2.flip(target, flip)\n",
    "\n",
    "  mask[mask >= 0.5] = 1\n",
    "  mask[mask < 0.5] = 0\n",
    "\n",
    "  mask = mask[128:384, 128:384, 0:3]\n",
    "  target = target[128:384, 128:384, 0:3]\n",
    "\n",
    "  if display:\n",
    "    _, axes = plt.subplots(2, 3, figsize=(15, 15))\n",
    "    axes[0, 0].imshow(background)\n",
    "    axes[0, 0].set_title(\"Background \" + str(background.shape))\n",
    "    axes[0, 0].axis(\"off\")\n",
    "\n",
    "    axes[0, 1].imshow(foreground)\n",
    "    axes[0, 1].set_title(\"Foreground \" + str(foreground.shape))\n",
    "    axes[0, 1].axis(\"off\")\n",
    "    \n",
    "    axes[0, 2].imshow(background_portion)\n",
    "    axes[0, 2].set_title(\"Background portion \" + str(background_portion.shape))\n",
    "    axes[0, 2].axis(\"off\")\n",
    "    \n",
    "    axes[1, 0].imshow(foreground_portion)\n",
    "    axes[1, 0].set_title(\"Foreground portion \" + str(foreground_portion.shape))\n",
    "    axes[1, 0].axis(\"off\")\n",
    "    \n",
    "    axes[1, 1].imshow(mask)\n",
    "    axes[1, 1].set_title(\"Mask \" + str(mask.shape))\n",
    "    axes[1, 1].axis(\"off\")\n",
    "    \n",
    "    axes[1, 2].imshow(target)\n",
    "    axes[1, 2].set_title(\"Target \" + str(target.shape))\n",
    "    axes[1, 2].axis(\"off\")\n",
    "\n",
    "  return target, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  model = UNet()\n",
    "  model = model.to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "  loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "  background = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "  foreground = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "  \n",
    "  model.train()\n",
    "\n",
    "  for epoch in range(EPOCHS):\n",
    "    targets = []\n",
    "    masks = []\n",
    "\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "      print('epoch:' + str(epoch + 1) + ' of ' + str(EPOCHS))\n",
    "\n",
    "    for i in range(IMAGES_PER_EPOCH):\n",
    "      #if (i + 1) % 128 == 0:\n",
    "      print('generating image: ' + str(i))\n",
    "      target, mask = generate_images(background, foreground, False)\n",
    "\n",
    "      targets.append(target)\n",
    "      masks.append(mask)\n",
    "\n",
    "    for i in range(len(targets)):\n",
    "      targets[i] = transpose(targets[i])\n",
    "\n",
    "    for i in range(len(masks)):\n",
    "      masks[i] = transpose(masks[i])\n",
    "\n",
    "    dataset = ImageDataset(targets, masks)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    for step, (target_batch, mask_batch) in enumerate(dataloader):\n",
    "      if (step + 1) % 100 == 0:\n",
    "        print('training image:' + str(step + 1) + ' of ' + str(len(dataloader)))\n",
    "\n",
    "      target_batch = target_batch.to(device)\n",
    "      mask_batch = mask_batch.to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      pred = model(target_batch)\n",
    "\n",
    "      loss = loss_fn(pred, mask_batch[0:1, 0:1, 0:SIZE, 0:SIZE])\n",
    "\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "\n",
    "  torch.save(model, \"text-segmentation.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating image: 0\n",
      "generating image: 1\n",
      "generating image: 2\n",
      "generating image: 3\n",
      "generating image: 4\n",
      "generating image: 5\n",
      "generating image: 6\n",
      "generating image: 7\n",
      "generating image: 8\n",
      "generating image: 9\n",
      "generating image: 0\n",
      "generating image: 1\n",
      "generating image: 2\n",
      "generating image: 3\n",
      "generating image: 4\n",
      "generating image: 5\n",
      "generating image: 6\n",
      "generating image: 7\n",
      "generating image: 8\n",
      "generating image: 9\n",
      "generating image: 0\n",
      "generating image: 1\n",
      "generating image: 2\n",
      "generating image: 3\n",
      "generating image: 4\n",
      "generating image: 5\n",
      "generating image: 6\n",
      "generating image: 7\n",
      "generating image: 8\n",
      "generating image: 9\n",
      "generating image: 0\n",
      "generating image: 1\n",
      "generating image: 2\n",
      "generating image: 3\n",
      "generating image: 4\n",
      "generating image: 5\n",
      "generating image: 6\n",
      "generating image: 7\n",
      "generating image: 8\n",
      "generating image: 9\n",
      "generating image: 0\n",
      "generating image: 1\n",
      "generating image: 2\n",
      "generating image: 3\n",
      "generating image: 4\n",
      "generating image: 5\n",
      "generating image: 6\n",
      "generating image: 7\n",
      "generating image: 8\n",
      "generating image: 9\n"
     ]
    }
   ],
   "source": [
    "#background = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "#foreground = load_image(TRAIN_FOLDER + random.choice(os.listdir(TRAIN_FOLDER)))\n",
    "#target, mask = generate_images(background, foreground, True)\n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "UNet                                     [1, 1, 256, 256]          --\n",
       "├─Connect: 1-1                           [1, 32, 256, 256]         --\n",
       "│    └─Conv2d: 2-1                       [1, 32, 256, 256]         896\n",
       "│    └─BatchNorm2d: 2-2                  [1, 32, 256, 256]         64\n",
       "│    └─ReLU: 2-3                         [1, 32, 256, 256]         --\n",
       "├─Connect: 1-2                           [1, 32, 256, 256]         --\n",
       "│    └─Conv2d: 2-4                       [1, 32, 256, 256]         9,248\n",
       "│    └─BatchNorm2d: 2-5                  [1, 32, 256, 256]         64\n",
       "│    └─ReLU: 2-6                         [1, 32, 256, 256]         --\n",
       "├─MaxPool2d: 1-3                         [1, 32, 128, 128]         --\n",
       "├─Connect: 1-4                           [1, 64, 128, 128]         --\n",
       "│    └─Conv2d: 2-7                       [1, 64, 128, 128]         18,496\n",
       "│    └─BatchNorm2d: 2-8                  [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-9                         [1, 64, 128, 128]         --\n",
       "├─Connect: 1-5                           [1, 64, 128, 128]         --\n",
       "│    └─Conv2d: 2-10                      [1, 64, 128, 128]         36,928\n",
       "│    └─BatchNorm2d: 2-11                 [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-12                        [1, 64, 128, 128]         --\n",
       "├─MaxPool2d: 1-6                         [1, 64, 64, 64]           --\n",
       "├─Connect: 1-7                           [1, 128, 64, 64]          --\n",
       "│    └─Conv2d: 2-13                      [1, 128, 64, 64]          73,856\n",
       "│    └─BatchNorm2d: 2-14                 [1, 128, 64, 64]          256\n",
       "│    └─ReLU: 2-15                        [1, 128, 64, 64]          --\n",
       "├─Connect: 1-8                           [1, 128, 64, 64]          --\n",
       "│    └─Conv2d: 2-16                      [1, 128, 64, 64]          147,584\n",
       "│    └─BatchNorm2d: 2-17                 [1, 128, 64, 64]          256\n",
       "│    └─ReLU: 2-18                        [1, 128, 64, 64]          --\n",
       "├─MaxPool2d: 1-9                         [1, 128, 32, 32]          --\n",
       "├─Connect: 1-10                          [1, 256, 32, 32]          --\n",
       "│    └─Conv2d: 2-19                      [1, 256, 32, 32]          295,168\n",
       "│    └─BatchNorm2d: 2-20                 [1, 256, 32, 32]          512\n",
       "│    └─ReLU: 2-21                        [1, 256, 32, 32]          --\n",
       "├─Connect: 1-11                          [1, 256, 32, 32]          --\n",
       "│    └─Conv2d: 2-22                      [1, 256, 32, 32]          590,080\n",
       "│    └─BatchNorm2d: 2-23                 [1, 256, 32, 32]          512\n",
       "│    └─ReLU: 2-24                        [1, 256, 32, 32]          --\n",
       "├─ConvTranspose2d: 1-12                  [1, 128, 64, 64]          131,200\n",
       "├─Connect: 1-13                          [1, 128, 64, 64]          --\n",
       "│    └─Conv2d: 2-25                      [1, 128, 64, 64]          295,040\n",
       "│    └─BatchNorm2d: 2-26                 [1, 128, 64, 64]          256\n",
       "│    └─ReLU: 2-27                        [1, 128, 64, 64]          --\n",
       "├─Connect: 1-14                          [1, 128, 64, 64]          --\n",
       "│    └─Conv2d: 2-28                      [1, 128, 64, 64]          147,584\n",
       "│    └─BatchNorm2d: 2-29                 [1, 128, 64, 64]          256\n",
       "│    └─ReLU: 2-30                        [1, 128, 64, 64]          --\n",
       "├─ConvTranspose2d: 1-15                  [1, 64, 128, 128]         32,832\n",
       "├─Connect: 1-16                          [1, 64, 128, 128]         --\n",
       "│    └─Conv2d: 2-31                      [1, 64, 128, 128]         73,792\n",
       "│    └─BatchNorm2d: 2-32                 [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-33                        [1, 64, 128, 128]         --\n",
       "├─Connect: 1-17                          [1, 64, 128, 128]         --\n",
       "│    └─Conv2d: 2-34                      [1, 64, 128, 128]         36,928\n",
       "│    └─BatchNorm2d: 2-35                 [1, 64, 128, 128]         128\n",
       "│    └─ReLU: 2-36                        [1, 64, 128, 128]         --\n",
       "├─ConvTranspose2d: 1-18                  [1, 32, 256, 256]         8,224\n",
       "├─Connect: 1-19                          [1, 32, 256, 256]         --\n",
       "│    └─Conv2d: 2-37                      [1, 32, 256, 256]         18,464\n",
       "│    └─BatchNorm2d: 2-38                 [1, 32, 256, 256]         64\n",
       "│    └─ReLU: 2-39                        [1, 32, 256, 256]         --\n",
       "├─Connect: 1-20                          [1, 32, 256, 256]         --\n",
       "│    └─Conv2d: 2-40                      [1, 32, 256, 256]         9,248\n",
       "│    └─BatchNorm2d: 2-41                 [1, 32, 256, 256]         64\n",
       "│    └─ReLU: 2-42                        [1, 32, 256, 256]         --\n",
       "├─Conv2d: 1-21                           [1, 1, 256, 256]          33\n",
       "==========================================================================================\n",
       "Total params: 1,928,417\n",
       "Trainable params: 1,928,417\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 10.45\n",
       "==========================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 273.15\n",
       "Params size (MB): 7.71\n",
       "Estimated Total Size (MB): 281.65\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(\"text-segmentation.pt\", map_location=device)\n",
    "torchinfo.summary(model, (1, 3, 256, 256), depth=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6532684ccaeb1bcbbe852b7f75c67e6f1d55df7d386020fd37670376cbe3d2c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
